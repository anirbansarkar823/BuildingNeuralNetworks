{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_on_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKvaMKR4-HGS"
      },
      "source": [
        "#### Without stride and padding: \n",
        "  * dimension of output layer = [input_dim - kernel_dim] + 1\n",
        "\n",
        "#### With stride (number of pixels kernel skips to jump to next multiplicaiton box) but no padding:\n",
        "  * dimension of output layer = ([input_dim - kernel_dim]/[stride_size]) + 1\n",
        "\n",
        "#### With stride and padding(extra 0's over all side of input, to keep the output of same size as input):\n",
        "  * dimension of output layer = ([input_dim - kernel_dim + 2 * padding_value]/[stride_size]) + 1\n",
        "\n",
        "#### Pooling: Pooling reduces the dimensions, but without using all important features, we can reduce the dimensionality. From each box, that kernel rolls over to, select the max. This is max pooling. Similar concept applies for avg pooling.\n",
        "  * dimension of output layer = (down_step_func[input_dim])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9EU0e8yzFOm",
        "outputId": "36479799-4057-4e66-c23f-a88755a522c2"
      },
      "source": [
        "# Credits: https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py\n",
        "\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "# normalizing the data\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "# defining the architecture\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Epoch 1/12\n",
            "469/469 [==============================] - 142s 301ms/step - loss: 0.2406 - accuracy: 0.9252 - val_loss: 0.0510 - val_accuracy: 0.9835\n",
            "Epoch 2/12\n",
            "469/469 [==============================] - 140s 299ms/step - loss: 0.0872 - accuracy: 0.9746 - val_loss: 0.0382 - val_accuracy: 0.9875\n",
            "Epoch 3/12\n",
            "469/469 [==============================] - 140s 298ms/step - loss: 0.0629 - accuracy: 0.9807 - val_loss: 0.0338 - val_accuracy: 0.9896\n",
            "Epoch 4/12\n",
            "469/469 [==============================] - 140s 299ms/step - loss: 0.0525 - accuracy: 0.9837 - val_loss: 0.0331 - val_accuracy: 0.9892\n",
            "Epoch 5/12\n",
            "469/469 [==============================] - 140s 298ms/step - loss: 0.0446 - accuracy: 0.9856 - val_loss: 0.0291 - val_accuracy: 0.9915\n",
            "Epoch 6/12\n",
            "469/469 [==============================] - 142s 302ms/step - loss: 0.0399 - accuracy: 0.9876 - val_loss: 0.0273 - val_accuracy: 0.9922\n",
            "Epoch 7/12\n",
            "469/469 [==============================] - 141s 300ms/step - loss: 0.0329 - accuracy: 0.9894 - val_loss: 0.0250 - val_accuracy: 0.9924\n",
            "Epoch 8/12\n",
            "469/469 [==============================] - 141s 301ms/step - loss: 0.0307 - accuracy: 0.9900 - val_loss: 0.0255 - val_accuracy: 0.9917\n",
            "Epoch 9/12\n",
            "469/469 [==============================] - 142s 303ms/step - loss: 0.0277 - accuracy: 0.9911 - val_loss: 0.0286 - val_accuracy: 0.9918\n",
            "Epoch 10/12\n",
            "469/469 [==============================] - 142s 302ms/step - loss: 0.0259 - accuracy: 0.9919 - val_loss: 0.0250 - val_accuracy: 0.9924\n",
            "Epoch 11/12\n",
            "469/469 [==============================] - 141s 301ms/step - loss: 0.0233 - accuracy: 0.9923 - val_loss: 0.0267 - val_accuracy: 0.9927\n",
            "Epoch 12/12\n",
            "469/469 [==============================] - 142s 303ms/step - loss: 0.0213 - accuracy: 0.9925 - val_loss: 0.0259 - val_accuracy: 0.9927\n",
            "Test loss: 0.025916485115885735\n",
            "Test accuracy: 0.9926999807357788\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHEg94O2Xawy",
        "outputId": "656d839d-3f60-4b00-9e4c-95514c49b819"
      },
      "source": [
        "# Credits: https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py\n",
        "\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Epoch 1/12\n",
            "469/469 [==============================] - 144s 306ms/step - loss: 0.2429 - accuracy: 0.9259 - val_loss: 0.0561 - val_accuracy: 0.9807\n",
            "Epoch 2/12\n",
            "469/469 [==============================] - 143s 305ms/step - loss: 0.0850 - accuracy: 0.9745 - val_loss: 0.0409 - val_accuracy: 0.9862\n",
            "Epoch 3/12\n",
            "469/469 [==============================] - 142s 303ms/step - loss: 0.0629 - accuracy: 0.9811 - val_loss: 0.0324 - val_accuracy: 0.9891\n",
            "Epoch 4/12\n",
            "469/469 [==============================] - 142s 303ms/step - loss: 0.0501 - accuracy: 0.9848 - val_loss: 0.0294 - val_accuracy: 0.9902\n",
            "Epoch 5/12\n",
            "469/469 [==============================] - 142s 303ms/step - loss: 0.0450 - accuracy: 0.9864 - val_loss: 0.0271 - val_accuracy: 0.9914\n",
            "Epoch 6/12\n",
            "469/469 [==============================] - 142s 302ms/step - loss: 0.0386 - accuracy: 0.9878 - val_loss: 0.0297 - val_accuracy: 0.9909\n",
            "Epoch 7/12\n",
            "469/469 [==============================] - 142s 303ms/step - loss: 0.0350 - accuracy: 0.9887 - val_loss: 0.0277 - val_accuracy: 0.9911\n",
            "Epoch 8/12\n",
            "469/469 [==============================] - 142s 304ms/step - loss: 0.0302 - accuracy: 0.9905 - val_loss: 0.0308 - val_accuracy: 0.9897\n",
            "Epoch 9/12\n",
            "469/469 [==============================] - 142s 302ms/step - loss: 0.0285 - accuracy: 0.9911 - val_loss: 0.0275 - val_accuracy: 0.9911\n",
            "Epoch 10/12\n",
            "469/469 [==============================] - 141s 301ms/step - loss: 0.0252 - accuracy: 0.9918 - val_loss: 0.0291 - val_accuracy: 0.9910\n",
            "Epoch 11/12\n",
            "469/469 [==============================] - 139s 296ms/step - loss: 0.0230 - accuracy: 0.9924 - val_loss: 0.0282 - val_accuracy: 0.9917\n",
            "Epoch 12/12\n",
            "469/469 [==============================] - 140s 298ms/step - loss: 0.0221 - accuracy: 0.9926 - val_loss: 0.0270 - val_accuracy: 0.9925\n",
            "Test loss: 0.02698303572833538\n",
            "Test accuracy: 0.9925000071525574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jjw2m_63XbDO"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    }
  ]
}